{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================\n",
    "#  calibration and comparison of uncertainty scores\n",
    "#  Does drop out generate good uncertainties?\n",
    "#...............................................................\n",
    "#\n",
    "\n",
    "# CHANGELOG\n",
    "#\n",
    "# 2020-05-26\n",
    "#   Translation to python3 by EA. Some operations changed in\n",
    "#   sequence of execution, some were replaced with for loops.\n",
    "\n",
    "#...............................................................\n",
    "# libraries\n",
    "import os  # read/change work dir\n",
    "import glob # list files on dir\n",
    "import numpy as np # fns used: unique\n",
    "import pandas as pd  # DataFrame is quite similar to R style\n",
    "#import statistics as st # fns used: median\n",
    "from math import exp  # only this function is used\n",
    "from scipy.interpolate import UnivariateSpline  # until a better function is found\n",
    "import matplotlib.pyplot as plt  # for plots\n",
    "\n",
    "#...............................................................\n",
    "# implementation of grep\n",
    "def grep(expr,vect,ret='index'):\n",
    "    ind = list(range(len(vect)))\n",
    "    log = [False]*len(vect)\n",
    "    for i in ind:\n",
    "        log[i] = (expr in vect[i])\n",
    "    if ret==\"index\":\n",
    "        return np.array(ind)[log].tolist()\n",
    "    if ret==\"logic\":\n",
    "        return log\n",
    "    if ret==\"value\":\n",
    "        return np.array(vect)[log].tolist()\n",
    "\n",
    "#...............................................................\n",
    "# input the data\n",
    "\n",
    "#os.chdir(\"~/LANL/Current/NCI-P1/ICML2020/ICML_Analysis\")\n",
    "\n",
    "ffiles = np.array(glob.glob(\"./**/*txt*\"))\n",
    "# NOTE ON SYNTAXIS:\n",
    "# ./**/ means: search in all subdirs, but not current dir\n",
    "# *txt* means: (SOMETH)txt(SOMETH); use one/two sides as needed\n",
    "\n",
    "datasets = [fname.split(\"\\\\\")[1] for fname in ffiles]\n",
    "# NOTE ON SYNTAXIS: arrays start at 0 on python, but at 1 in R\n",
    "\n",
    "model_type = np.array( [\"hom\"]*len(ffiles) )\n",
    "idx = grep(\"het\",ffiles,ret=\"logic\")\n",
    "model_type[idx] = [\"het\"]*len(idx)\n",
    "model_type = model_type.tolist()\n",
    "# NOTES ON SYNTAXIS:\n",
    "# R variable names can have dots, but in Python is not allowed\n",
    "# Python lists can't be indexed by lists, but numpy arrays can\n",
    "\n",
    "idx_hom = [mt==\"hom\" for mt in model_type]\n",
    "idx_het = [mt==\"het\" for mt in model_type]\n",
    "\n",
    "#  pick a dataset\n",
    "for dat_name in np.unique(datasets):\n",
    "    idx_data = grep(dat_name,datasets,ret=\"logic\")\n",
    "    \n",
    "    # read the datasets\n",
    "    #... homogeneuous model\n",
    "    dat_hom = ( pd.read_csv(file,header=False,sep=\" \") \\\n",
    "              for file in ffiles[idx_data and idx_hom][0] )\n",
    "    dat_hom.index = [\"true\"] + [\"E.\"+str(i) for i in range(1,201)]\n",
    "    rep_hom = list(range(2,202))\n",
    "    # NOTES ON SYNTAXIS:\n",
    "    # range(1,200) does not include 200, so 201 is used\n",
    "    # index =is= rownames, columns =is= colnames\n",
    "    \n",
    "    #... heterogeneuous model\n",
    "    dat_het = ( pd.read_csv(file,header=False,sep=\" \") \\\n",
    "              for file in ffiles[idx_data and idx_het][0] )\n",
    "    dat_het.index = [\"true\"] + \\\n",
    "                [\"E.\"+str(i)+\"S.\"+str(i) for i in range(1,201)]\n",
    "    rep_het = list(range(2,202))*2 # different code, same result\n",
    "    rep_het.sort()\n",
    "    \n",
    "    #................\n",
    "    #  response\n",
    "    Y = dat_het[\"true\"]\n",
    "    \n",
    "    #................\n",
    "    # Score S1 mean abs dev of hetero pred \n",
    "    idxE = grep(\"E.\",dat_het.columns,ret=\"val\")\n",
    "    fbar_het = dat_het[:,idxE].median(axis=1)\n",
    "    nc = len(idxE)\n",
    "    nr = len(fbar_het)\n",
    "    #Mbar = \n",
    "    S1 = [st.median([abs(dat_het[rr,idxE])-fbar_het[rr]])\\\n",
    "          for rr in dat_het.index]\n",
    "    \n",
    "    # Score S2 is median of sd\n",
    "    idxS = grep(\"S.\",dat_het.columns,ret=\"val\")\n",
    "    S2 = [st.median([exp(dat_het[rr,ii]/2) for ii in idxS])\\\n",
    "          for rr in dat_het.index]\n",
    "    \n",
    "    # Score S3 is mean abs of homo\n",
    "    idxE = grep(\"E.\",dat_hom.columns,ret=\"val\")\n",
    "    fbar_hom = dat_hom[:,idxE].median(axis=1)\n",
    "    nc = len(idxE)\n",
    "    nr = len(fbar_hom)\n",
    "    #Mbar = \n",
    "    S3 = [st.median([abs(dat_hom[rr,idxE])-fbar_hom[rr]])\\\n",
    "          for rr in dat_hom.index]\n",
    "    \n",
    "\n",
    "    #.....\n",
    "    # Loss\n",
    "    Z1 = abs( Y - fbar_hom )  # for homogeneaous model\n",
    "    Z2 = abs( Y - fbar_het )  # for hetogeneaous model\n",
    "    \n",
    "    #######################################################\n",
    "    # Calibration (using ranks)\n",
    "    \n",
    "    # randomized tiebraker is achieved by first randomizing\n",
    "    # the vector, then using rank, then ordering again\n",
    "    x1 = S1.sample(frac=1).rank(method='first').reindex_like(S1)\n",
    "    s1 = x1.argsort()\n",
    "    z1 = [ Z1[idx] for idx in s1]\n",
    "    xs1 = x1.sort()\n",
    "    ss1 = UnivariateSpline(xs1,z1,\\\n",
    "                           k=4)  # degree of smoothing spline)\n",
    "    f1 = ss1(xs1)\n",
    "    \n",
    "    # Note: Looking for a suitable equivalent for smooth.spline\n",
    "    #   with cross-validation in python.\n",
    "    \n",
    "    x2 = S2.sample(frac=1).rank(method='first').reindex_like(S2)\n",
    "    s2 = x2.argsort()\n",
    "    z2 = [ Z1[idx] for idx in s2]\n",
    "    xs2 = x2.sort()\n",
    "    ss2 = UnivariateSpline(xs2,z2,\\\n",
    "                           k=4)  # degree of smoothing spline)\n",
    "    f2 = ss2(xs2)\n",
    "    \n",
    "    x3 = S3.sample(frac=1).rank(method='first').reindex_like(S3)\n",
    "    s3 = x3.argsort()\n",
    "    z3 = [ Z2[idx] for idx in s3]\n",
    "    xs3 = x3.sort()\n",
    "    ss3 = UnivariateSpline(xs3,z3,\\\n",
    "                           k=4)  # degree of smoothing spline)\n",
    "    f3 = ss3(xs3)\n",
    "    \n",
    "    #........................\n",
    "    #  make plots\n",
    "    mm = max(f1+f2+f3)\n",
    "    plt.figure()\n",
    "    #plt.plot(x1,ss1(x1),marker='.')\n",
    "    # NOTE ON SYNTAXIS:\n",
    "    # Rplot requires an empty plot to pre-set axis, but pyplot doesn't\n",
    "    \n",
    "    plt.ylim(0,mm)\n",
    "    plt.xlabel(\"stardardized score\")\n",
    "    plt.ylabel(\"calibrated score\")\n",
    "    plt.title(dat_name)\n",
    "    \n",
    "    plt.plot(xs1,f1,\"r\",label=\"S1\")\n",
    "    plt.plot(xs2,f2,\"g\",label=\"S2\")\n",
    "    plt.plot(xs3,f3,\"b\",label=\"S3\")\n",
    "    \n",
    "    plt.legend(loc=\"upper left\",markerscale=3.0)\n",
    "    \n",
    "    plt.show\n",
    "\n",
    "# \\/-- untested\n",
    "#plt.savefig(\"calibration.pdf\")  # file is created after plot is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
